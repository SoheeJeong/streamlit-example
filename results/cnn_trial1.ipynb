{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    istj\n",
       "1    istj\n",
       "2    istj\n",
       "3    istj\n",
       "4    istj\n",
       "Name: MBTI, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv('crop/all.csv')\n",
    "\n",
    "photo_df = pd.DataFrame(columns=['photo'], dtype= 'object')\n",
    "\n",
    "# put the photo data into a dataframe\n",
    "for i in range(len(mbti_df)):\n",
    "    image = transform(Image.open('crop/' + mbti_df['file_name'][i]))\n",
    "    photo_df.loc[i] = [image]\n",
    "\n",
    "mbti_df = mbti_df['MBTI']\n",
    "\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df.iloc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = ['s', 'n']\n",
    "\n",
    "# if mbti_df['MBTI'] includes alphabet[0], then mbti_df['MBTI'] = 1, else 0\n",
    "mbti_df = mbti_df.apply(lambda x: 1 if alphabet[0] in x else 0)\n",
    "\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    578\n",
      "1    467\n",
      "Name: MBTI, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the statistics of the mbti_df\n",
    "print(mbti_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data includes the element of 2-dim tensor\n",
    "train_data = photo_df['photo'].values\n",
    "train_label = mbti_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 data 중 train의 비율\n",
    "train_ratio = 0.6\n",
    "\n",
    "train_idx = np.random.choice(len(train_data), int(len(train_data) * train_ratio), replace=False)\n",
    "test_idx = np.array(list(set(range(len(train_data))) - set(train_idx)))\n",
    "\n",
    "test_data = train_data[test_idx]\n",
    "test_label = train_label[test_idx]\n",
    "\n",
    "train_data = train_data[train_idx]\n",
    "train_label = train_label[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MBTI_Dataset(Dataset):\n",
    "    def __init__(self, train_label, train_data):\n",
    "        self.train_label = train_label\n",
    "        self.train_data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        mbti = self.train_label[idx]\n",
    "        photo = self.train_data[idx]\n",
    "\n",
    "        return mbti, photo\n",
    "\n",
    "# parameter 값은 이것을 변경해주세요\n",
    "in_ch1 = 1\n",
    "out_ch1 = 6\n",
    "ker1 = 4\n",
    "stride1 = 1\n",
    "pad1 = 2\n",
    "\n",
    "out_ch2 = 16\n",
    "ker2 = 3\n",
    "stride2 = 1\n",
    "pad2 = 0\n",
    "\n",
    "out_ch3 = 32\n",
    "ker3 = 2\n",
    "stride3 = 1\n",
    "pad3 = 0\n",
    "\n",
    "out_ch4 = 64\n",
    "ker4 = 2\n",
    "stride4 = 1\n",
    "pad4 = 0\n",
    "\n",
    "out_ch5 = 128\n",
    "ker5 = 2\n",
    "stride5 = 1\n",
    "pad5 = 0\n",
    "\n",
    "\n",
    "pool_size1 = 3\n",
    "pool_size2 = 2\n",
    "pool_size3 = 2\n",
    "pool_size4 = 2\n",
    "pool_size5 = 2\n",
    "\n",
    "\n",
    "out_feat1 = 120\n",
    "out_feat2 = 84\n",
    "out_feat3 = 1\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net, self).__init__()\n",
    "        input_height, input_width = input_shape\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_ch1, out_channels = out_ch1, kernel_size = ker1, stride = stride1, padding = pad1)\n",
    "        self.pool1 = nn.MaxPool2d(pool_size1, pool_size1)\n",
    "\n",
    "        output1_height, output1_width = (input_height - ker1 + 2 * pad1) / stride1 + 1, (input_width - ker1 + 2 * pad1) / stride1 + 1\n",
    "        output1_height, output1_width = int(output1_height / pool_size1), int(output1_width / pool_size1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = out_ch1, out_channels = out_ch2, kernel_size = ker2, stride = stride2, padding = pad2)\n",
    "        self.pool2 = nn.MaxPool2d(pool_size2, pool_size2)\n",
    "\n",
    "        output2_height, output2_width = (output1_height - ker2 + 2 * pad2) / stride2 + 1, (output1_width - ker2 + 2 * pad2) / stride2 + 1\n",
    "        output2_height, output2_width = int(output2_height / pool_size2), int(output2_width / pool_size2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels = out_ch2, out_channels = out_ch3, kernel_size = ker3, stride = stride3, padding = pad3)\n",
    "        self.pool3 = nn.MaxPool2d(pool_size3, pool_size3)\n",
    "\n",
    "        output3_height, output3_width = (output2_height - ker3 + 2 * pad3) / stride3 + 1, (output2_width - ker3 + 2 * pad3) / stride3 + 1\n",
    "        output3_height, output3_width = int(output3_height / pool_size3), int(output3_width / pool_size3)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels = out_ch3, out_channels = out_ch4, kernel_size = ker4, stride = stride4, padding = pad4)\n",
    "        self.pool4 = nn.MaxPool2d(pool_size4, pool_size4)\n",
    "\n",
    "        output4_height, output4_width = (output3_height - ker4 + 2 * pad4) / stride4 + 1, (output3_width - ker4 + 2 * pad4) / stride4 + 1\n",
    "        output4_height, output4_width = int(output4_height / pool_size4), int(output4_width / pool_size4)\n",
    "\n",
    "        self.fc1 = nn.Linear(out_ch4 * output4_height * output4_width, out_feat1)\n",
    "        self.fc2 = nn.Linear(out_feat1, out_feat2)\n",
    "        self.fc3 = nn.Linear(out_feat2, out_feat3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        #print('1')\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        #print('2')\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        #print('3')\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        #print('4')\n",
    "        #x = self.pool5(F.relu(self.conv5(x)))\n",
    "        #print('5')\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # 이 부분은 변경하셔도 괜찮아요. relu로 할지 sigmoid로 할지\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class cnn_model():\n",
    "    def __init__(self, model, lr=0.01, epochs=100, momentum = 0.6):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.momentum = momentum\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, momentum = self.momentum)\n",
    "    \n",
    "    def fit(self, X_train, y_train):        \n",
    "        self.trainloader = DataLoader(MBTI_Dataset(X_train, y_train), batch_size=64, shuffle=False)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, data in enumerate(self.trainloader):\n",
    "                inputs, labels = data\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                labels.unsqueeze_(1)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(x.unsqueeze(0))\n",
    "        return y_pred\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'lr': self.lr, 'epochs': self.epochs, 'momentum': self.momentum}\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net((train_data[0].shape[1], train_data[0].shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cross_val_score(model, train_data, label, cv=5):\n",
    "    k = cv\n",
    "    kf = KFold(n_splits=k, random_state=42, shuffle=True)\n",
    "\n",
    "    acc_score = []\n",
    "    auc_score = []\n",
    "    \n",
    "    for train_index , test_index in kf.split(train_data):\n",
    "        X_train , X_test = train_data[train_index],train_data[test_index]\n",
    "        y_train , y_test = label[train_index] , label[test_index]\n",
    "        \n",
    "        if(np.unique(y_test).shape[0] == 1):\n",
    "            print('only one class')\n",
    "            continue\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        pred_values = []\n",
    "\n",
    "        for i in range(len(X_test)):\n",
    "            pred = model.predict(X_test[i])\n",
    "            pred_values.append(pred.item())\n",
    "\n",
    "        auc = roc_auc_score(y_test, pred_values)\n",
    "        auc_score.append(auc)\n",
    "        \n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "    avg_auc_score = sum(auc_score)/k\n",
    "    \n",
    "    return avg_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tupes of (lr, momentum, epochs) randomly\n",
    "# random cv를 몇번 돌릴 것인지...\n",
    "random_cv_num = 20\n",
    "\n",
    "\n",
    "# parameter 값이 이 범위 내에서 나옵니다\n",
    "lrs = np.linspace(0.01, 0.06, 30)\n",
    "momentums = np.linspace(0.0, 0.9, 20)\n",
    "epochss = np.linspace(50, 200, 5, dtype=int)\n",
    "\n",
    "params = [(lr, momentum, epochs) for lr in lrs for momentum in momentums for epochs in epochss]\n",
    "np.random.shuffle(params)\n",
    "params = params[:random_cv_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m cv_params \u001b[39m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m----> 7\u001b[0m     cv_scores\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(cross_val_score(model, train_data, train_label, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)))\n\u001b[0;32m      8\u001b[0m     cv_params\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mget_params())\n\u001b[0;32m     10\u001b[0m cv_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(cv_scores)\n",
      "Cell \u001b[1;32mIn [11], line 20\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(model, train_data, label, cv)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39monly one class\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     22\u001b[0m pred_values \u001b[39m=\u001b[39m []\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_test)):\n",
      "Cell \u001b[1;32mIn [9], line 137\u001b[0m, in \u001b[0;36mcnn_model.fit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m    135\u001b[0m labels\u001b[39m.\u001b[39munsqueeze_(\u001b[39m1\u001b[39m)\n\u001b[0;32m    136\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m--> 137\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\opush\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\opush\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [cnn_model(net, lr, epochs, momentum) for lr, momentum, epochs in params]\n",
    "\n",
    "cv_scores = []\n",
    "cv_params = []\n",
    "\n",
    "for model in models:\n",
    "    cv_scores.append(np.mean(cross_val_score(model, train_data, train_label, cv=3)))\n",
    "    cv_params.append(model.get_params())\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "cv_params = np.array(cv_params)\n",
    "\n",
    "best_params = cv_params[np.argmax(cv_scores)]\n",
    "best_score = np.max(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lr:  0.047931034482758615 Best momentum:  0.0 Best epochs:  125\n"
     ]
    }
   ],
   "source": [
    "print('Best lr: ', best_params['lr'], 'Best momentum: ', best_params['momentum'], 'Best epochs: ', best_params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold:  0.6791999999998151\n",
      "Best score for train set:  0.5502392344497608\n",
      "0.5334928229665071\n",
      "0.5287081339712919\n",
      "the model is  0.4784688995215225 % better than random guess\n",
      "roc auc score:  0.5221420860417576\n"
     ]
    }
   ],
   "source": [
    "#import roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#calculate test accuracy score\n",
    "#model = cnn_model(model = net, lr = best_params['lr'], momentum = best_params['momentum'], epochs = best_params['epochs'])\n",
    "model = cnn_model(model = net, lr = 0.04, momentum = 0, epochs = 125)\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "train_pred_values = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    pred = model.predict(train_data[i])\n",
    "    train_pred_values.append(pred.item())\n",
    "\n",
    "#calculate mean and variance of train_pred\n",
    "train_pred_values = np.array(train_pred_values)\n",
    "train_pred_mean = np.mean(train_pred_values)\n",
    "train_pred_var = np.var(train_pred_values)\n",
    "\n",
    "#normalize train_pred_values\n",
    "train_pred_values = (train_pred_values - train_pred_mean) / np.sqrt(train_pred_var)\n",
    "\n",
    "# draw the histogram of train_pred_values\n",
    "plt.hist(train_pred_values, bins=100)\n",
    "plt.show()\n",
    "\n",
    "best_threshold = 0\n",
    "best_score = 0\n",
    "\n",
    "for threshold in np.arange(-1, 1, 0.0001):\n",
    "    y_pred = np.array(train_pred_values) > threshold\n",
    "    score = accuracy_score(train_label, y_pred)\n",
    "    if score > best_score:\n",
    "        best_threshold = threshold\n",
    "        best_score = score\n",
    "\n",
    "print('Best threshold: ', best_threshold)\n",
    "print('Best score for train set: ', best_score)\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = model.predict(test_data[i])\n",
    "    pred_values.append(pred.item())\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#normalize pred_values\n",
    "pred_values = (pred_values - train_pred_mean) / np.sqrt(train_pred_var)\n",
    "guess3 = roc_auc_score(test_label, pred_values)\n",
    "\n",
    "pred_values[pred_values >= best_threshold] = 1\n",
    "pred_values[pred_values < best_threshold] = 0\n",
    "\n",
    "#calculate accuracy score\n",
    "\n",
    "guess1 = accuracy_score(test_label, pred_values)\n",
    "print(guess1)\n",
    "\n",
    "# random guess\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = 0\n",
    "    pred_values.append(pred)\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#calculate accuracy score\n",
    "guess2 = accuracy_score(test_label, pred_values)\n",
    "print(guess2)\n",
    "\n",
    "print('the model is ', (guess1 - guess2)*100, '% better than random guess')\n",
    "\n",
    "print('roc auc score: ', guess3)\n",
    "\n",
    "# save the model\n",
    "model.save('cnn_trial1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5717703349282297\n"
     ]
    }
   ],
   "source": [
    "# random guess\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = 0\n",
    "    pred_values.append(pred)\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#calculate accuracy score\n",
    "guess2 = accuracy_score(test_label, pred_values)\n",
    "print(guess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is  -2.8708133971291905 % better than random guess\n"
     ]
    }
   ],
   "source": [
    "print('the model is ', (guess1 - guess2)*100, '% better than random guess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score:  0.551444630248978\n"
     ]
    }
   ],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(test_label, pred_values)\n",
    "\n",
    "# calculate the best quantize threshold using roc curve\n",
    "best_threshold = 0\n",
    "\n",
    "for i in range(len(fpr)):\n",
    "    if fpr[i] >= 0.1 and fpr[i] <= 0.2:\n",
    "        best_threshold = thresholds[i]\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = model.predict(test_data[i])\n",
    "    pred_values.append(pred.item())\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#normalize pred_values\n",
    "pred_values = (pred_values - train_pred_mean) / np.sqrt(train_pred_var)\n",
    "\n",
    "guess3 = roc_auc_score(test_label, pred_values)\n",
    "\n",
    "pred_values[pred_values >= best_threshold] = 1\n",
    "pred_values[pred_values < best_threshold] = 0\n",
    "\n",
    "#calculate roc score\n",
    "print('roc auc score: ', guess3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('PyTorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e6deea03f373b4c861bc3d562619dfb3a773dcf49daa365d4720af764a85b00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
